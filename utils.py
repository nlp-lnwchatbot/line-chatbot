import pandas as pd
import numpy as np
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from pythainlp import word_tokenize
from pythainlp.util import dict_trie
from pythainlp.corpus.common import thai_words
from pythainlp.corpus import thai_stopwords
import re

custom_dict_thai_word = {
    "‡∏≠‡∏±‡∏•‡∏ï‡∏£‡πâ‡∏≤",
    "11PM",
    "720p",
    "‡∏Ñ‡∏£‡∏¥‡∏™‡∏ï‡∏±‡∏™",
    "‡πÄ‡∏ô‡πá‡∏ï‡∏ü‡∏•‡∏¥‡∏Å",
    "p5",
    "ps5",
    "4k",
    "‡πÅ‡∏≠‡∏ô‡∏î‡∏£‡∏≠‡∏¢",
    "‡∏ó‡∏∏‡∏Å‡∏£‡∏∏‡πà‡∏ô",
    "‡πÄ‡∏≠‡πÄ‡∏ö‡∏¥‡∏•‡πÄ‡∏°‡πá‡∏ô",
    "‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤",
    "‡πÑ‡∏ó‡πÄ‡∏ó‡πÄ‡∏ô‡∏µ‡πà‡∏¢‡∏°",
    "‡πÄ‡∏≠‡πÑ‡∏≠",
    "‡∏à‡∏∏‡∏á‡πÄ‡∏ö‡∏¢",
    "‡πÅ‡∏´‡∏•‡πà‡∏∞",
    "ps4",
    "iphone",
    "A17",
    "‡πÑ‡∏ó‡πÄ‡∏ó",
    "s23",
    "‡πÅ‡∏≠‡∏õ",
    "i15",
    "i14",
    "i13",
    "i12",
    "i11",
    "‡πÄ‡πÄ‡∏°‡∏£‡πà‡∏á",
    "‡∏¢‡∏π‡∏ó‡∏π‡∏õ",
    "5G",
    "‡∏î‡∏£‡∏≠‡∏õ",
    "‡πÄ‡πÄ‡∏•‡∏∞",
    "‡∏û‡∏±‡∏ö‡∏à‡∏µ",
    "‡πÄ‡πÄ‡∏û‡∏á",
    "‡πÄ‡πÄ‡∏¢‡∏Å",
    "‡πÄ‡πÄ‡∏ó‡∏ö",
    "‡∏ä‡∏≤‡∏à",
    "‡∏ó‡∏ß‡∏¥‡∏ï",
    "‡πÑ‡∏≠‡∏à‡∏µ",
    "‡πÅ‡∏•‡πâ‡∏ß",
    "‡πÄ‡∏Ñ‡∏™",
    "‡∏ï‡∏≤‡∏•‡∏∏‡∏Å‡∏ß‡∏≤‡∏ß",
    "IP15",
    "IP14",
    "ip15",
    "ip14",
    "‡πÄ‡πÄ‡∏£‡∏á",
    "‡∏ö‡∏≠‡∏Å",
    "‡∏ï‡∏π‡πâ‡∏°",
    "‡∏≠‡∏∏‡∏™‡πà‡∏≤‡∏´‡πå",
    "‡∏Å‡πà‡∏≠‡∏ô",
    "‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡πå",
    "‡πÅ‡∏•‡∏Ñ",
    "‡∏ß‡∏≠‡∏ó",
    "‡πÅ‡∏°‡πà‡∏á",
    "‡πÄ‡∏Å‡∏ô‡∏ä‡∏¥‡∏ô",
    "‡πÅ‡∏õ‡∏õ",
    "‡πÄ‡∏Ñ‡∏£‡∏°",
    "‡∏õ‡∏±‡∏à‡πÉ‡∏à",
    "‡∏ä‡∏¥‡∏ü",
    "‡∏ö‡∏•‡∏≤",
    "‡∏≠‡∏∏‡πà‡∏ô‡∏†‡∏π‡∏°‡∏¥",
    "‡πÑ‡∏•‡∏ô‡πå‡∏ô‡∏¥‡πà‡∏á",
    "‡∏™‡πÅ‡∏õ‡∏Ñ",
    "‡∏Ñ‡∏≠‡πÄ‡∏Å‡∏°",
    "‡πÅ‡∏≠‡∏ô‡∏î‡∏≠‡∏¢",
    "‡∏≠‡∏¥‡∏ô‡∏ü‡∏•‡∏π",
    "‡πÇ‡∏ã‡πÄ‡∏ä‡∏µ‡∏¢‡∏•",
    "‡∏à‡∏≤‡∏Å",
    "‡πÄ‡∏Å‡∏°‡πÄ‡∏°‡∏≠‡∏£‡πå",
    "‡∏™‡∏ô‡πâ‡∏ö‡∏™‡∏ô‡∏∏‡∏ô",
    "‡∏≠‡∏µ‡∏™‡∏õ‡∏≠‡∏£‡πå‡∏ï",
    "‡πÑ‡∏ß‡πÄ‡∏•‡∏™",
    "‡∏°‡πâ‡∏≤‡∏Å",
    "‡πÄ‡∏õ‡∏•‡∏µ‡πâ‡∏¢‡∏ô",
    "‡πÅ‡∏≠‡∏ô‡∏î‡∏≠‡∏¢",
    "‡πÄ‡∏Å‡∏°‡∏°‡∏¥‡∏á",
    "‡∏°‡∏≤‡∏Å",
    "‡∏Ñ‡∏≠‡∏ô‡∏ó‡∏£‡πà‡∏≤",
    "‡πÄ‡∏°‡∏°",
    "‡πÇ‡∏≠‡πà‡∏ß",
    "‡∏≠‡∏≠‡∏ô‡∏î‡∏£‡∏≠‡∏¢",
    "‡πÇ‡∏≠‡πÄ‡∏≠‡∏™",
    "‡∏Å‡πà‡∏≠‡∏ô",
    "‡πÅ‡∏≠‡∏ô‡∏î‡∏≠‡∏£‡∏¢‡πå",
    "‡∏û‡∏≠‡∏ã",
    "‡πÄ‡∏Å‡∏°‡∏°‡∏¥‡πà‡∏á",
    "‡πÇ‡∏≠‡πÄ‡∏Ñ‡∏£‡πâ",
    "‡πÑ‡∏≠‡πÅ‡∏•‡∏ô‡∏î‡πå",
    "‡∏•‡∏µ‡πà‡∏ô‡∏õ‡∏∑‡πâ‡∏î",
    "15",
    "14",
    "‡πÅ‡∏°‡πâ‡∏Å",
    "‡πÄ‡∏´‡∏ô",
    "‡πÇ‡∏Ñ‡∏£‡∏ï",
    "‡∏£‡∏≤‡∏Ñ‡∏≤",
    "‡∏Ñ‡∏°‡∏£‡∏∞‡πÄ‡∏Ñ‡∏∑‡∏≠‡∏á",
    "‡∏†‡∏≤‡∏û",
    "‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ",
    "‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢",
    "‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà",
    "‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å",
    "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤",
    "‡πÑ‡∏°‡πà‡∏£‡πâ‡∏≠‡∏ô",
}

thai_word_set = set(thai_words())
custom_dict_thai_word.update(thai_word_set)
trie = dict_trie(dict_source=custom_dict_thai_word)

STOP_WORD = list(thai_stopwords()) + [" ", "\n", "‡πÜ"]
STOP_WORD.remove("‡πÑ‡∏°‡πà")
FORMAT = r"[\u0E00-\u0E7Fa-zA-Z'0-9]+"


def tokenize(sentence):
    return word_tokenize(
        sentence, engine="newmm", keep_whitespace=False, custom_dict=trie
    )


def cleaning_stop_word(tk_list):
    return [word.replace("‡πÜ", "") for word in tk_list if word not in STOP_WORD]


def cleaning_symbols_emoji(tk_list):
    return [re.findall(FORMAT, text)[0] for text in tk_list if re.findall(FORMAT, text)]


def big_cleaning(sentence):
    tokens = cleaning_symbols_emoji(cleaning_stop_word(tokenize(sentence)))
    return tokens


df_0 = pd.read_csv("./data/class_0.csv")
df_1 = pd.read_csv("./data/class_1.csv")
frame = [df_0, df_1]
data = pd.concat(frame, ignore_index=True)

x = data["text"].apply(big_cleaning).astype(str)
tokenizer = Tokenizer()
tokenizer.fit_on_texts(x)
x = tokenizer.texts_to_sequences(x)
x = pad_sequences(x)


def predict_class(model, dataframeToPredict, threshold=0.6):
    dataframeToPredict = dataframeToPredict["message"].apply(big_cleaning).astype(str)
    dataframeToPredict = tokenizer.texts_to_sequences(dataframeToPredict)
    padded_sequence = pad_sequences(dataframeToPredict, maxlen=x.shape[1])

    lstm_pred = model.predict(padded_sequence)

    lstm_label = np.argmax(lstm_pred, axis=1)

    lstm_label[lstm_pred.max(axis=1) < threshold] = -1

    check = np.where(
        lstm_label == 0,
        "Positive üòÅ",
        np.where(lstm_label == 1, "Negative üò°", "Neutral"),
    )
    return check
